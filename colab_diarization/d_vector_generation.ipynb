{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d-vector_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "itckvlZVCa3s",
        "2Arqvyesf1yi",
        "CrmIs27VQYge",
        "eBaf4L52V2zC",
        "wOaphJyPrtyb",
        "-vudRKZVwQWo",
        "vNeKlGpkJivh",
        "fSAvdWONvQZM",
        "CXuTg8t0vTDo",
        "qgR2Ft4Ucy3i",
        "TvIxwEMm4abg",
        "rYLWilgbUUBz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itckvlZVCa3s"
      },
      "source": [
        "## Manage Colab Env/WD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4r2W4r5FMEJ",
        "outputId": "5db872a9-dd99-435a-cd3b-e239bde7ea2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLz5L63sdHCz"
      },
      "source": [
        "import json\n",
        "from datetime import date\n",
        "import traceback\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import collections\n",
        "import contextlib\n",
        "import sys\n",
        "import wave\n",
        "\n",
        "term = '2020'\n",
        "docket = '18-540'\n",
        "mod_path = \"/content/model.model\"\n",
        "ap = '18-540_20201006-argument.delivery.mp3'\n",
        "ap_wav = '18-540_argument.wav'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqJmgSMfCL_4",
        "outputId": "9e51b7ad-e8f4-4e71-e8bf-83682ebfca6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -ag"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root 4096 Oct 31 20:14 .\n",
            "drwxr-xr-x 1 root 4096 Oct 31 20:10 ..\n",
            "drwxr-xr-x 1 root 4096 Oct 28 16:30 .config\n",
            "drwx------ 5 root 4096 Oct 31 20:14 drive\n",
            "drwxr-xr-x 1 root 4096 Oct 28 16:30 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SAB-VO1dTgd",
        "outputId": "4449635b-1b7a-4681-c818-797c3c1551b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls drive/My\\ Drive/1006:\\ Term\\ Project/Colab\\ Notebooks/ -ag"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 55518\n",
            "-rw------- 1 root  7915975 Oct 19 00:53 case_summaries.json\n",
            "drwx------ 2 root     4096 Oct 19 02:28 config\n",
            "-rw------- 1 root     2684 Oct 18 16:50 data_load.py\n",
            "-rw------- 1 root     3405 Oct 18 21:54 data_preprocess.py\n",
            "-rw------- 1 root     4018 Oct 12 00:54 dvector_create.py\n",
            "-rw------- 1 root    65693 Oct 24 20:00 d-vector_generation.ipynb\n",
            "-rw------- 1 root     1591 Oct 18 16:51 hparam.py\n",
            "-rw------- 1 root 48543272 Oct 19 17:53 model.model\n",
            "drwx------ 2 root     4096 Oct 23 17:32 notes\n",
            "drwx------ 2 root     4096 Oct 23 14:01 oyez_parser\n",
            "drwx------ 2 root     4096 Oct 19 02:54 __pycache__\n",
            "-rw------- 1 root    11539 Oct 19 17:58 run_TIMIT_test.ipynb\n",
            "-rw------- 1 root   251947 Oct 19 17:43 run_train.ipynb\n",
            "-rw------- 1 root     1595 Oct 18 16:56 speech_embedder_net.py\n",
            "drwx------ 2 root     4096 Oct 30 18:32 speech_id_checkpoint_1019\n",
            "lrw------- 1 root        0 Oct 24 17:49 test_tisv -> '/content/drive/ '\n",
            "-rw------- 1 root     7109 Oct 18 21:56 train_speech_embedder.py\n",
            "drwx------ 2 root     4096 Oct 19 02:28 train_tisv\n",
            "-rw------- 1 root     6890 Oct 18 16:52 utils.py\n",
            "-rw------- 1 root     5817 Oct 12 00:54 VAD_segments.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31vsWwpvCKQL",
        "outputId": "eb3d6998-c22a-4133-89d6-0f300b9f4867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls drive/My\\ Drive/Colab\\ Notebooks/diarization -ag"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 68\n",
            "-rw------- 1 root 65005 Oct 31 20:42 d-vector_generation.ipynb\n",
            "-rw------- 1 root  4377 Oct 19 01:56 PyTorchSV.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Arqvyesf1yi"
      },
      "source": [
        "# Get desired audio file + transript/times from web \n",
        "  - mostly to understand audio data scraping tools\n",
        "  - test utilization in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUyBIhLeIR2"
      },
      "source": [
        "# Add court summaries file to WD\n",
        "!cp drive/My\\ Drive/1006:\\ Term\\ Project/Colab\\ Notebooks/case_summaries.json /content/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTNdtDUPcGe3"
      },
      "source": [
        "def get_http_json(url):\n",
        "    print(f\"Getting {url}\")\n",
        "    response = requests.get(url)\n",
        "    parsed = response.json()\n",
        "    return parsed\n",
        "\n",
        "def get_case(term, docket):\n",
        "    \"\"\"Get the info of the case and fetch all\n",
        "    transcripts that the info links to\"\"\"\n",
        "    url = f\"https://api.oyez.org/cases/{term}/{docket}\"\n",
        "    docket_data = get_http_json(url)\n",
        "\n",
        "    if not (\n",
        "        \"oral_argument_audio\" in docket_data and docket_data[\"oral_argument_audio\"]\n",
        "    ):\n",
        "        # no oral arguments for this case yet\n",
        "        # fail so we will try again later\n",
        "        print(f\"No oral arguments for docket {docket}\")\n",
        "        return (docket_data, [])\n",
        "\n",
        "    oral_argument_audio = docket_data[\"oral_argument_audio\"]\n",
        "    transcripts = []\n",
        "    for link in oral_argument_audio:\n",
        "        t = get_http_json(link[\"href\"])\n",
        "        transcripts.append(t)\n",
        "\n",
        "    return docket_data, transcripts\n",
        "\n",
        "def getTranscript(transcripts):\n",
        "    transcript_list = []\n",
        "    speaker_list = []\n",
        "    speaker_type_list = []\n",
        "    time_list = []\n",
        "    \n",
        "    for t in transcripts:\n",
        "        sections = t['transcript']['sections']\n",
        "        for section in sections:\n",
        "            turns = section['turns']\n",
        "            for turn in turns:\n",
        "                \n",
        "                try:\n",
        "                    speaker = turn['speaker']['name']\n",
        "                except:\n",
        "                    speaker = '<UNK>'\n",
        "                speaker_list.append(speaker)   \n",
        "                \n",
        "                roles = turn['speaker']['roles']\n",
        "                if isinstance(roles, list):\n",
        "                    multiple_roles = []\n",
        "                    for role in roles:\n",
        "                        multiple_roles.append(role['type'])\n",
        "                    speaker_type_list.append(multiple_roles)\n",
        "                \n",
        "                else:\n",
        "                    speaker_type_list.append(['Other']) #Other is most likely Lawyer\n",
        "                \n",
        "                \n",
        "                texts = turn['text_blocks']\n",
        "                texts_out = []\n",
        "                times_out = []\n",
        "                for text in texts:\n",
        "                    texts_out.append(text['text'])\n",
        "                    times_out.append((text['start'],text['stop']))\n",
        "                \n",
        "                transcript_list.append(texts_out)\n",
        "                time_list.append(times_out)\n",
        "\n",
        "    return transcript_list, speaker_list, speaker_type_list, time_list\n",
        "\n",
        "def getAudio(transcripts):\n",
        "    num_files = len(transcripts)\n",
        "    audio_list = []\n",
        "    for t in transcripts:\n",
        "        media_dicts = t['media_file']\n",
        "        #just incase theres more than one, there shouldnt be but they re in a weird list\n",
        "        for media_dict in media_dicts:\n",
        "            audio_list.append(media_dict['href'])\n",
        "    return [num_files,audio_list]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUUPilq4cUuO"
      },
      "source": [
        "# Get all the terms and dockets from case_summaries.json file\n",
        "with open(os.getcwd() + '/case_summaries.json') as f:\n",
        "    data = json.load(f)\n",
        "    \n",
        "case_summaries = pd.DataFrame(data)\n",
        "case_summaries = case_summaries[['term', 'docket_number']]\n",
        "# Let's start with 2020\n",
        "case_summaries_2020 = case_summaries[case_summaries['term']=='2020']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v82V-iQYcUr6",
        "outputId": "238dc5a5-e0b4-4c49-8aaf-16dc78e12c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = {}\n",
        "\n",
        "for term, docket_number in case_summaries_2020.itertuples(index=False):\n",
        "    docket_data, transcripts = get_case(term, docket_number)\n",
        "    data[docket_number] = transcripts"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting https://api.oyez.org/cases/2020/18-540\n",
            "Getting https://api.oyez.org/case_media/oral_argument_audio/25077\n",
            "Getting https://api.oyez.org/cases/2020/19-71\n",
            "Getting https://api.oyez.org/case_media/oral_argument_audio/25058\n",
            "Getting https://api.oyez.org/cases/2020/19-368\n",
            "Getting https://api.oyez.org/case_media/oral_argument_audio/25061\n",
            "Getting https://api.oyez.org/cases/2020/19-309\n",
            "Getting https://api.oyez.org/case_media/oral_argument_audio/25055\n",
            "Getting https://api.oyez.org/cases/2020/18-956\n",
            "Getting https://api.oyez.org/case_media/oral_argument_audio/25068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZT68ScOcGg0"
      },
      "source": [
        "audio_path = getAudio(data[docket])[1][0].strip(\"'\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfKMKPS3aj6O"
      },
      "source": [
        "transcript_list, speaker_list, speaker_type_list, time_list = getTranscript(transcripts)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSkxgNfhfLBi",
        "outputId": "d37d6a5a-0a33-4053-cc33-a51d12161df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "?#Add mp3 file to WD as determined thru getAudio function\n",
        "!wget $audio_path"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-31 20:44:16--  https://s3.amazonaws.com/oyez.case-media.mp3/case_data/2020/18-540/18-540_20201006-argument.delivery.mp3\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.86.78\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.86.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17200673 (16M) [audio/mpeg]\n",
            "Saving to: ‘18-540_20201006-argument.delivery.mp3’\n",
            "\n",
            "18-540_20201006-arg 100%[===================>]  16.40M  97.0MB/s    in 0.2s    \n",
            "\n",
            "2020-10-31 20:44:17 (97.0 MB/s) - ‘18-540_20201006-argument.delivery.mp3’ saved [17200673/17200673]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrmIs27VQYge"
      },
      "source": [
        "# Define and Load SpeechEmbedder()\n",
        "  - Manually define SpeechEmbedder (could use import, demands files)\n",
        "  - manually load model checkpoint `mod_path`\n",
        "  - can resave, continue training, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-3PphVrgc4v"
      },
      "source": [
        "#### copy necessary files for defining network\n",
        "  - hparam.py\n",
        "  - config/config.yaml\n",
        "  - utils.py\n",
        "  - model checkpoint `model.model`\n",
        "  - could import all files (not necessary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICP0Lddvggqw"
      },
      "source": [
        "!cp drive/My\\ Drive/1006:\\ Term\\ Project/Colab\\ Notebooks/model.model /content/"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCGUdCBtH0mA"
      },
      "source": [
        "!cp -r drive/My\\ Drive/1006:\\ Term\\ Project/Colab\\ Notebooks/config ."
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9renJnD6QJz9"
      },
      "source": [
        "!cp drive/My\\ Drive/1006:\\ Term\\ Project/Colab\\ Notebooks/hparam.py ."
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQDi_yDXQM8w"
      },
      "source": [
        "!cp drive/My\\ Drive/1006:\\ Term\\ Project/Colab\\ Notebooks/utils.py ."
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_VKlp51HuxV"
      },
      "source": [
        "#Add PyTorch_SV git repo files from google drive to colab drive mount (/content/)\n",
        "#!cp -r drive/My\\ Drive/1006:\\ Term\\ Project/Colab\\ Notebooks/*.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRw57WUDH3Rk",
        "outputId": "b50c68f3-97ea-416b-a707-984b07c969ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls  -ag"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 71976\n",
            "drwxr-xr-x 1 root     4096 Oct 31 20:50 .\n",
            "drwxr-xr-x 1 root     4096 Oct 31 20:10 ..\n",
            "-rw-r--r-- 1 root 17200673 Oct 22 16:15 18-540_20201006-argument.delivery.mp3\n",
            "-rw------- 1 root  7915975 Oct 31 20:44 case_summaries.json\n",
            "drwx------ 2 root     4096 Oct 31 20:50 config\n",
            "drwxr-xr-x 1 root     4096 Oct 28 16:30 .config\n",
            "drwx------ 5 root     4096 Oct 31 20:14 drive\n",
            "-rw------- 1 root     1591 Oct 31 20:50 hparam.py\n",
            "-rw------- 1 root 48543272 Oct 31 20:50 model.model\n",
            "drwxr-xr-x 1 root     4096 Oct 28 16:30 sample_data\n",
            "-rw------- 1 root     6890 Oct 31 20:50 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBaf4L52V2zC"
      },
      "source": [
        "#### Load SpeechEmbedder\n",
        "  - embedder_net w/ final checkpoint params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VraFYD_n54F"
      },
      "source": [
        "from hparam import hparam as hp\n",
        "from utils import get_centroids, get_cossim, calc_loss\n",
        "\n",
        "class SpeechEmbedder(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SpeechEmbedder, self).__init__()    \n",
        "        self.LSTM_stack = nn.LSTM(hp.data.nmels, hp.model.hidden, num_layers=hp.model.num_layer, batch_first=True)\n",
        "        for name, param in self.LSTM_stack.named_parameters():\n",
        "          if 'bias' in name:\n",
        "             nn.init.constant_(param, 0.0)\n",
        "          elif 'weight' in name:\n",
        "             nn.init.xavier_normal_(param)\n",
        "        self.projection = nn.Linear(hp.model.hidden, hp.model.proj)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x, _ = self.LSTM_stack(x.float()) #(batch, frames, n_mels)\n",
        "        #only use last frame\n",
        "        x = x[:,x.size(1)-1]\n",
        "        x = self.projection(x.float())\n",
        "        x = x / torch.norm(x, dim=1).unsqueeze(1)\n",
        "        return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StY6W6KIg4kZ"
      },
      "source": [
        "embedder_net = SpeechEmbedder()\n",
        "chk = torch.load(mod_path)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQGgRnvSl81f",
        "outputId": "09046619-f94f-4aae-a884-0a11f0ff7667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embedder_net.load_state_dict(chk)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZtiKe1BEK0o"
      },
      "source": [
        "#Add TIMIT test data to colab drive mount (if you want to evaluate model)\n",
        "#!cp -r drive/My\\ Drive/1006\\ Colab\\ Notebooks/test_tisv ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgTOJShApvjo"
      },
      "source": [
        "# Resave model as state_dict\n",
        "#torch.save(model.state_dict(), \"drive/My Drive/Colab Notebooks/model_statedict.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOaphJyPrtyb"
      },
      "source": [
        "# d-Vector engineering\n",
        "  - process audio file\n",
        "  - compile `dvector_create.py` inner training loop for single (full) argument\n",
        "  - output embedding of argument (subsample of argument)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vudRKZVwQWo"
      },
      "source": [
        "#### colab package installs\n",
        "  - install/import webrtcvad (VAD_chunk)\n",
        "  - install/import pydub (mp3 $\\rightarrow$ wav)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV6vE2BDhklW",
        "outputId": "c7a2c879-4d66-4cf2-f7e3-d7db3aa1e0d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install webrtcvad in google colab (must be ran every time)\n",
        "!pip install webrtcvad"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting webrtcvad\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/34/e2de2d97f3288512b9ea56f92e7452f8207eb5a0096500badf9dfd48f5e6/webrtcvad-2.0.10.tar.gz (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 26.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 27.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 25.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51kB 11.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp36-cp36m-linux_x86_64.whl size=71404 sha256=9b063a426cf0aa7ed5909c1b97455e4bde6bea1b276297ff3a930f74a7c84a07\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/2a/18/bd1aec41cac7c3051fe95d92a6ed446122ea31dc713c432fa1\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wBqK6NqNhMr",
        "outputId": "cbbd0cc2-f9a1-428b-9569-546d5968157c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.24.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpKR-8bNlrBu"
      },
      "source": [
        "import pydub\n",
        "import webrtcvad"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNeKlGpkJivh"
      },
      "source": [
        "### Construct Single d-vector manually\n",
        "  - independently define `dvector_create.py, VAD_segments.py` functions\n",
        "  - mp3 (could be flacc) audio file  $\\rightarrow$ properly sampled .wav \n",
        "  - .wav $\\rightarrow$ STFT representation of full audio file\n",
        "  - Analyze speaker alignment challenge (for labelled data)\n",
        "  - `VAD_chunk()`, `concat_segs()`, `get_STFT()`\n",
        "  - utilize `SpeechEmbedder()`\n",
        "  - *ToDo: perform alignment concatenation*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSAvdWONvQZM"
      },
      "source": [
        "#### .py functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tiG-mrHijGv"
      },
      "source": [
        "def concat_segs(times, segs):\n",
        "    #Concatenate continuous voiced segments\n",
        "    concat_seg = []\n",
        "    seg_concat = segs[0]\n",
        "    for i in range(0, len(times)-1):\n",
        "        if times[i][1] == times[i+1][0]:\n",
        "            seg_concat = np.concatenate((seg_concat, segs[i+1]))\n",
        "        else:\n",
        "            concat_seg.append(seg_concat)\n",
        "            seg_concat = segs[i+1]\n",
        "    else:\n",
        "        concat_seg.append(seg_concat)\n",
        "    return concat_seg\n",
        "\n",
        "def get_STFTs(segs):\n",
        "    #Get 240ms STFT windows with 50% overlap\n",
        "    sr = hp.data.sr\n",
        "    STFT_frames = []\n",
        "    for seg in segs:\n",
        "        S = librosa.core.stft(y=seg, n_fft=hp.data.nfft,\n",
        "                              win_length=int(hp.data.window * sr), hop_length=int(hp.data.hop * sr))\n",
        "        S = np.abs(S)**2\n",
        "        mel_basis = librosa.filters.mel(sr, n_fft=hp.data.nfft, n_mels=hp.data.nmels)\n",
        "        S = np.log10(np.dot(mel_basis, S) + 1e-6)           # log mel spectrogram of utterances\n",
        "        for j in range(0, S.shape[1], int(.12/hp.data.hop)):\n",
        "            if j + 24 < S.shape[1]:\n",
        "                STFT_frames.append(S[:,j:j+24])\n",
        "            else:\n",
        "                break\n",
        "    return STFT_frames\n",
        "\n",
        "def align_embeddings(embeddings):\n",
        "    partitions = []\n",
        "    start = 0\n",
        "    end = 0\n",
        "    j = 1\n",
        "    for i, embedding in enumerate(embeddings):\n",
        "        if (i*.12)+.24 < j*.401:\n",
        "            end = end + 1\n",
        "        else:\n",
        "            partitions.append((start,end))\n",
        "            start = end\n",
        "            end = end + 1\n",
        "            j += 1\n",
        "    else:\n",
        "        partitions.append((start,end))\n",
        "    avg_embeddings = np.zeros((len(partitions),256))\n",
        "    for i, partition in enumerate(partitions):\n",
        "        avg_embeddings[i] = np.average(embeddings[partition[0]:partition[1]],axis=0) \n",
        "    return avg_embeddings\n",
        "\n",
        "\n",
        "def read_wave(path, sr):\n",
        "    \"\"\"Reads a .wav file.\n",
        "    Takes the path, and returns (PCM audio data, sample rate).\n",
        "    Assumes sample width == 2\n",
        "    \"\"\"\n",
        "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "        num_channels = wf.getnchannels()\n",
        "        assert num_channels == 1\n",
        "        sample_width = wf.getsampwidth()\n",
        "        assert sample_width == 2\n",
        "        sample_rate = wf.getframerate()\n",
        "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "        pcm_data = wf.readframes(wf.getnframes())\n",
        "    data, _ = librosa.load(path, sr)\n",
        "    assert len(data.shape) == 1\n",
        "    assert sr in (8000, 16000, 32000, 48000)\n",
        "    return data, pcm_data\n",
        "    \n",
        "class Frame(object):\n",
        "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
        "    def __init__(self, bytes, timestamp, duration):\n",
        "        self.bytes = bytes\n",
        "        self.timestamp = timestamp\n",
        "        self.duration = duration\n",
        "\n",
        "\n",
        "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "    \"\"\"Generates audio frames from PCM audio data.\n",
        "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
        "    the sample rate.\n",
        "    Yields Frames of the requested duration.\n",
        "    \"\"\"\n",
        "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "    offset = 0\n",
        "    timestamp = 0.0\n",
        "    duration = (float(n) / sample_rate) / 2.0\n",
        "    while offset + n < len(audio):\n",
        "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "        timestamp += duration\n",
        "        offset += n\n",
        "\n",
        "\n",
        "def vad_collector(sample_rate, frame_duration_ms,\n",
        "                  padding_duration_ms, vad, frames):\n",
        "    \"\"\"Filters out non-voiced audio frames.\n",
        "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
        "    the voiced audio.\n",
        "    Uses a padded, sliding window algorithm over the audio frames.\n",
        "    When more than 90% of the frames in the window are voiced (as\n",
        "    reported by the VAD), the collector triggers and begins yielding\n",
        "    audio frames. Then the collector waits until 90% of the frames in\n",
        "    the window are unvoiced to detrigger.\n",
        "    The window is padded at the front and back to provide a small\n",
        "    amount of silence or the beginnings/endings of speech around the\n",
        "    voiced frames.\n",
        "    Arguments:\n",
        "    sample_rate - The audio sample rate, in Hz.\n",
        "    frame_duration_ms - The frame duration in milliseconds.\n",
        "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
        "    vad - An instance of webrtcvad.Vad.\n",
        "    frames - a source of audio frames (sequence or generator).\n",
        "    Returns: A generator that yields PCM audio data.\n",
        "    \"\"\"\n",
        "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
        "    # We use a deque for our sliding window/ring buffer.\n",
        "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
        "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
        "    # NOTTRIGGERED state.\n",
        "    triggered = False\n",
        "\n",
        "    voiced_frames = []\n",
        "    for frame in frames:\n",
        "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
        "\n",
        "        if not triggered:\n",
        "            ring_buffer.append((frame, is_speech))\n",
        "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
        "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
        "            # the ring buffer are voiced frames, then enter the\n",
        "            # TRIGGERED state.\n",
        "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
        "                triggered = True\n",
        "                start = ring_buffer[0][0].timestamp\n",
        "                # We want to yield all the audio we see from now until\n",
        "                # we are NOTTRIGGERED, but we have to start with the\n",
        "                # audio that's already in the ring buffer.\n",
        "                for f, s in ring_buffer:\n",
        "                    voiced_frames.append(f)\n",
        "                ring_buffer.clear()\n",
        "        else:\n",
        "            # We're in the TRIGGERED state, so collect the audio data\n",
        "            # and add it to the ring buffer.\n",
        "            voiced_frames.append(frame)\n",
        "            ring_buffer.append((frame, is_speech))\n",
        "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
        "            # If more than 90% of the frames in the ring buffer are\n",
        "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
        "            # audio we've collected.\n",
        "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
        "                triggered = False\n",
        "                yield (start, frame.timestamp + frame.duration)\n",
        "                ring_buffer.clear()\n",
        "                voiced_frames = []\n",
        "    # If we have any leftover voiced audio when we run out of input,\n",
        "    # yield it.\n",
        "    if voiced_frames:\n",
        "        yield (start, frame.timestamp + frame.duration)\n",
        "\n",
        "\n",
        "def VAD_chunk(aggressiveness, path):\n",
        "    audio, byte_audio = read_wave(path, hp.data.sr)\n",
        "    vad = webrtcvad.Vad(int(aggressiveness))\n",
        "    frames = frame_generator(20, byte_audio, hp.data.sr)\n",
        "    frames = list(frames)\n",
        "    times = vad_collector(hp.data.sr, 20, 200, vad, frames)\n",
        "    speech_times = []\n",
        "    speech_segs = []\n",
        "    for i, time in enumerate(times):\n",
        "        start = np.round(time[0],decimals=2)\n",
        "        end = np.round(time[1],decimals=2)\n",
        "        j = start\n",
        "        while j + .4 < end:\n",
        "            end_j = np.round(j+.4,decimals=2)\n",
        "            speech_times.append((j, end_j))\n",
        "            speech_segs.append(audio[int(j*hp.data.sr):int(end_j*hp.data.sr)])\n",
        "            j = end_j\n",
        "        else:\n",
        "            speech_times.append((j, end))\n",
        "            speech_segs.append(audio[int(j*hp.data.sr):int(end*hp.data.sr)])\n",
        "    return speech_times, speech_segs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXuTg8t0vTDo"
      },
      "source": [
        "#### audio processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "602Dx5s2OY9x",
        "outputId": "a32e6779-d90a-41c8-e2f9-3da0c07e4e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#mp3 to wav with predefined frame_rate/sample_rate \n",
        "\n",
        "#!rm 18-540_argument.wav\n",
        "sound = pydub.AudioSegment.from_mp3(ap)\n",
        "sound = sound.set_frame_rate(hp.data.sr)\n",
        "sound.export(ap_wav, format=\"wav\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='18-540_argument.wav'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5UHw4hlKG4T"
      },
      "source": [
        "train_sequence = []\n",
        "train_cluster_id = []\n",
        "label = 0\n",
        "count = 0\n",
        "train_saved = False"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0cP6ekJmc0i"
      },
      "source": [
        "'''\n",
        "2 -> webrtcvad.Vad(2)\n",
        "webrtcvad github: aggressiveness mode, \n",
        "which is an integer between 0 and 3. \n",
        "0 is the least aggressive about \n",
        "filtering out non-speech, \n",
        "3 is the most aggressive.\n",
        "'''\n",
        "\n",
        "times, segs = VAD_chunk(2, ap_wav)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tks6PE7Ubscv"
      },
      "source": [
        "##### Analyzing Speaker Alignment Issue\n",
        "  -  d-vectorization process re-organizes sound\n",
        "  - need to retain alignment\n",
        "  -  generally, sound-transcription aligning should be handled in `concat_segs`\n",
        "  - **Since we are engineering our data to enter the pipeline in the same format/structure as the original implementation, we need to link each resulting embedding with its start & end time then we just concatenate all the embeddings for a case in the proper order and keep the labels**\n",
        "\n",
        "Methodology:\n",
        "  + sentence/utterance (however we divide it) by **one** speaker enters pipeline\n",
        "    - comes with time started, time ended\n",
        "  + utterance gets chopped up (`VAD_chunk()`, `concat_segs()`, `get_STFT()`) => LMS (slices X log-melspectrogram)\n",
        "    - we lose where each word takes place in time in this process, but I dont think we care\n",
        "  + LMS -> SpeechEmbedder() => `embeddings` (slices X 256)\n",
        "  + tuple time started, time ended, `embeddings` & add to list \n",
        "  + order list & concat embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc-kI5dPc5NM",
        "outputId": "3e1399db-66b8-4f95-c456-d01e28fd43f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(time_list)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcGo1zN6dfaU"
      },
      "source": [
        "t = []\n",
        "for tl in time_list:\n",
        "  t.append(tl[-1][-1])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQse0tRwc7Be",
        "outputId": "936263d6-c0ec-46a5-9f50-ccbb779744b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(t)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqSVW321eNM2",
        "outputId": "91a1be6b-a8db-4ff7-b4be-eb9506c91f94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t[0:5]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.24, 140.96, 161.56, 176.72, 177.48]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWLZjwlmdGMe",
        "outputId": "49f00d89-14a4-49bb-9917-caecf76195d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "time_list[0:5]"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 7.24)],\n",
              " [(7.24, 15.56),\n",
              "  (15.56, 18.76),\n",
              "  (18.76, 28.64),\n",
              "  (28.64, 63.52),\n",
              "  (63.52, 75.72),\n",
              "  (75.72, 90.12),\n",
              "  (90.12, 96.64),\n",
              "  (96.64, 109),\n",
              "  (109, 115.04),\n",
              "  (115.04, 120.68),\n",
              "  (120.68, 131.48),\n",
              "  (131.48, 140.96)],\n",
              " [(140.96, 161.56)],\n",
              " [(161.56, 161.92), (161.92, 163.88), (163.88, 168.36), (168.36, 176.72)],\n",
              " [(176.72, 177.48)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjHaaDoDdTHR",
        "outputId": "b2339324-6018-4574-8a7b-3cbb2cb002db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transcript_list[0]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We will hear argument first this morning in Case 18-956, Google versus Oracle. Mr. Goldstein.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cio3Lpe3dVbS",
        "outputId": "55d61d0b-05f7-4fbd-c58a-0ac241243706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transcript_list[1]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mr. Chief Justice, and may it please the Court: The merger doctrine resolved the copyrightability question in this case.',\n",
              " 'Oracle has a copyright to the computer code in Java SE but not a patent.',\n",
              " \"That means that the public, not Oracle, has the right to Java SE's function, and Oracle cannot leverage its copyright to create patent-like rights.\",\n",
              " \"Specifically, under the merger doctrine, there is no copyright protection for computer code that is the only way to perform those functions. Here, Java software developers have the right to use certain commands to create applications for Google's Android smartphone platform, but, to work, the commands require Google to reuse an exact set of declarations from Java SE, like a key that fits into a lock. Because there are no substitutes, Oracle is impermissibly claiming the exclusive right not merely to what the declarations say but also to what the declarations do.\",\n",
              " 'That is not a copyright; it is a patent right. With respect to fair use, the long-settled practice of reusing software interfaces is critical to modern interoperable computer software.',\n",
              " 'Here, reusing the minimally creative declarations allowed the developers to write millions of creative applications that are used by more than a billion people. But those policy questions are almost academic because the issue is not whether this Court would find fair use.',\n",
              " 'The standard of review asks the much narrower question whether the jury could reasonably find fair use.',\n",
              " 'Oracle now obviously regrets its demand that the jury weigh all the evidence and decide fair use in a general verdict that contains no subsidiary findings. No previous court ever held that only a court may decide fair use.',\n",
              " 'It is so fact-bound that no prior appellate court ever overturned a fair use verdict.',\n",
              " 'This uniquely contested case should not be the first. Today, you will hear three lawyers present legal arguments for an hour.',\n",
              " 'In 2016, the jury heard the starkly conflicting testimony of almost 30 witnesses and reviewed roughly 200 exhibits over two-and-a-half weeks.',\n",
              " 'This case perfectly illustrates, as this Court recently reiterated in Georgia versus Public.Resource, that fair use \"is notoriously fact-sensitive and often cannot be resolved without a trial.\" Thank you.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgR2Ft4Ucy3i"
      },
      "source": [
        "#### audio processing contd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuaZ0Pl73_Qv"
      },
      "source": [
        "# probably where we will need to \n",
        "# keep track of our alignment \n",
        "# with speaker labels\n",
        "concat_seg = concat_segs(times, segs)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_VU2a0WcMi2",
        "outputId": "2ee717e2-1994-4890-bd8e-6a833963f6a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(concat_seg)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "573"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7idVELWymc21",
        "outputId": "dde32e61-bd66-4383-a28a-e75fd9df3555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(times))\n",
        "print(type(times[0]))\n",
        "print(type(segs))\n",
        "print(type(segs[0]))\n",
        "print(\"times[0]:\", times[0])\n",
        "print(\"times[1]:\", times[1])\n",
        "print(\"times[-2]:\", times[-2])\n",
        "print(\"times[-1]:\", times[-1])\n",
        "print(\"segs[0] shape:\", np.shape(segs[0])[0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'tuple'>\n",
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "times[0]: (0.1, 0.5)\n",
            "times[1]: (0.5, 0.9)\n",
            "times[-2]: (4292.4, 4292.8)\n",
            "times[-1]: (4292.8, 4292.82)\n",
            "segs[0] shape: 6400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KqPkP8dmc5F",
        "outputId": "3989782e-55b4-4fcf-cf9c-3c886f1fbd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Visualization of sound wave estimation \n",
        "# for time slice where voice activity is detected\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(np.shape(segs[0])[0]), segs[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_991f6Bmc-r"
      },
      "source": [
        "'''\n",
        "Short Time Fourier Transform\n",
        "from function comments: 240ms STFT windows with 50% overlap\n",
        "outputs 40 X 24 -> \n",
        "  - 40=number of mel energies (hparam)\n",
        "  - 24 = ?...\n",
        "'''\n",
        "STFT_frames = get_STFTs(concat_seg)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eee9Dogghc3O",
        "outputId": "e127e4bc-3b8a-4eae-b5f0-e25d24631a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(STFT_frames)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKMDB79Vg7rL",
        "outputId": "454a6ea7-0dd4-42a6-d228-781ff884edb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(concat_seg)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "573"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ff2rXFrp6tu",
        "outputId": "d6181e7d-908d-40fe-b5c7-58e79d36a4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"# frames (depends on file size):\", len(STFT_frames))\n",
        "print(\"Predefined output shape:\", np.shape(STFT_frames[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# frames (depends on file size): 33349\n",
            "Predefined output shape: (40, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MktoMXJVp6xh",
        "outputId": "3b0ef73f-9282-4985-af90-9482c0ed1d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# reshape & convert to tensor\n",
        "STFT_frames = np.stack(STFT_frames, axis=2)\n",
        "STFT_frames = torch.tensor(np.transpose(STFT_frames, axes=(2,1,0)))\n",
        "print(\"STFT size:\", STFT_frames.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STFT size: torch.Size([33349, 24, 40])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPpWMuqV2ofK"
      },
      "source": [
        "# 33349 to large for available RAM in Colab (total of 10GB i think!)\n",
        "# 500 slice limit sample for testing\n",
        "# send to device here to save RAM\n",
        "STFT_sample = STFT_frames[0:500, :, :].to(hp.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvIxwEMm4abg"
      },
      "source": [
        "#### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ_yU36oqZcN"
      },
      "source": [
        "# Generate embedding\n",
        "# model will be on eval for court arguments\n",
        "embedder_net.eval()\n",
        "embedder_net.to(hp.device)\n",
        "embeddings = embedder_net(STFT_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R24cQQ5_2fIg",
        "outputId": "66cca01c-7305-41bc-b31a-ba5b71ecfba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuXRL5USxrdb",
        "outputId": "30449395-e3c3-4013-9f4f-2b0023e15d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "# our first dvector \n",
        "embeddings[0,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1240,  0.0455,  0.0003,  0.0453,  0.0002,  0.1131,  0.0588,  0.0170,\n",
              "         0.0087, -0.0361, -0.0113,  0.0544, -0.0334, -0.0327, -0.0378,  0.0191,\n",
              "         0.0196, -0.0374, -0.0074,  0.0381, -0.0815, -0.0518, -0.0827, -0.1062,\n",
              "        -0.0139,  0.0607,  0.1170, -0.0645,  0.0676,  0.0091, -0.0537, -0.0237,\n",
              "        -0.0245, -0.0499, -0.0737, -0.0739,  0.2134,  0.0644,  0.0091,  0.0070,\n",
              "         0.0435, -0.0402,  0.0098, -0.0025, -0.0934,  0.0739, -0.0394,  0.0501,\n",
              "         0.0916,  0.0941,  0.0465, -0.0052, -0.0636,  0.0353,  0.0458, -0.1032,\n",
              "         0.0343, -0.0608, -0.0391,  0.0025,  0.0645,  0.0642, -0.0426, -0.0322,\n",
              "         0.0850, -0.1075, -0.1069, -0.1096, -0.0256,  0.0701, -0.0467, -0.0091,\n",
              "        -0.1201, -0.0914,  0.0242,  0.0347, -0.0058,  0.0011, -0.0058,  0.0547,\n",
              "         0.0149,  0.0378, -0.0487,  0.0207,  0.0200,  0.0044,  0.0593, -0.0604,\n",
              "        -0.0488, -0.0832,  0.0082, -0.0368,  0.0276,  0.0317, -0.0365,  0.0466,\n",
              "        -0.0534, -0.0883, -0.0082,  0.0701, -0.0056,  0.0529, -0.0500,  0.0043,\n",
              "        -0.0537, -0.0520, -0.0078, -0.0873, -0.0107,  0.1432, -0.0697,  0.0952,\n",
              "        -0.0328,  0.0831,  0.0506, -0.0526,  0.0331, -0.0358,  0.0224,  0.0028,\n",
              "         0.1003,  0.0558, -0.1688, -0.0307,  0.1427, -0.0493, -0.0142, -0.0062,\n",
              "         0.0253,  0.1076,  0.1138,  0.0186,  0.0581, -0.0142, -0.0490, -0.0625,\n",
              "         0.0581, -0.0159,  0.0968,  0.0849,  0.0742, -0.0149, -0.0178,  0.0090,\n",
              "         0.0349, -0.0108,  0.0592, -0.0189,  0.0484,  0.0164,  0.0090,  0.0074,\n",
              "        -0.0521, -0.0590, -0.0966, -0.0468, -0.0414,  0.0637, -0.0571, -0.0455,\n",
              "        -0.0593,  0.0069,  0.0646, -0.0044, -0.1524, -0.0231, -0.0173, -0.1141,\n",
              "         0.0245,  0.0044, -0.0979,  0.0381,  0.2154, -0.0191, -0.0405,  0.0853,\n",
              "         0.0485,  0.0195, -0.0625, -0.0065, -0.0302,  0.0025, -0.0280, -0.1440,\n",
              "        -0.0723, -0.0425, -0.0315, -0.0650, -0.0395, -0.0367,  0.0060,  0.0064,\n",
              "        -0.0061,  0.0406, -0.0544,  0.0320,  0.0489, -0.0166, -0.0450,  0.0059,\n",
              "         0.1162, -0.1441,  0.0310,  0.0096, -0.0252, -0.1320, -0.0144, -0.0247,\n",
              "         0.0899, -0.0178,  0.0103,  0.1224,  0.0155,  0.0266, -0.0244,  0.0266,\n",
              "        -0.0578,  0.0156,  0.0322,  0.0051,  0.0949,  0.0425, -0.0514,  0.1042,\n",
              "         0.0225,  0.0567,  0.1584, -0.0947,  0.0187, -0.0122, -0.0457,  0.0240,\n",
              "        -0.0957, -0.0221, -0.0109, -0.0620, -0.0255,  0.0632,  0.0968, -0.0360,\n",
              "         0.0757, -0.0147, -0.0575,  0.0960,  0.0879,  0.0088,  0.0389, -0.0156,\n",
              "         0.0532,  0.0243, -0.0038,  0.0459,  0.0446,  0.0534, -0.0974,  0.0761],\n",
              "       device='cuda:0', grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYLWilgbUUBz"
      },
      "source": [
        "# PyTorch SV dvector_create guts\n",
        "  - dont run, just for reference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve38TPitLf3w"
      },
      "source": [
        "times, segs = VAD_chunk(2, ap_wav)\n",
        "if segs == []:\n",
        "    print('No voice activity detected')\n",
        "else:\n",
        "  print(\"proceeding\") \n",
        "concat_seg = concat_segs(times, segs)\n",
        "STFT_frames = get_STFTs(concat_seg)\n",
        "STFT_frames = np.stack(STFT_frames, axis=2)\n",
        "STFT_frames = torch.tensor(np.transpose(STFT_frames, axes=(2,1,0)))\n",
        "print(\"up to embedder\")\n",
        "embeddings = embedder_net(STFT_frames)\n",
        "aligned_embeddings = align_embeddings(embeddings.detach().numpy())\n",
        "train_sequence.append(aligned_embeddings)\n",
        "for embedding in aligned_embeddings:\n",
        "    train_cluster_id.append(str(label))\n",
        "if count == 0:\n",
        "    print('Processed {0}/{1} files'.format(count, len(audio_path)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohlYQAkbRblt",
        "outputId": "fa6fde9d-9a9f-466a-f87d-fbf260d86032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = ap_wav\n",
        "with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "  print(\"test:\", wf.getframerate())\n",
        "  num_channels = wf.getnchannels()\n",
        "  assert num_channels == 1\n",
        "  sample_width = wf.getsampwidth()\n",
        "  assert sample_width == 2\n",
        "  sample_rate = wf.getframerate()\n",
        "  assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "  pcm_data = wf.readframes(wf.getnframes())\n",
        "data, _ = librosa.load(path, sr)\n",
        "assert len(data.shape) == 1\n",
        "assert sr in (8000, 16000, 32000, 48000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test: 16000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WE9BmurJoi5"
      },
      "source": [
        "train_sequence = np.concatenate(train_sequence,axis=0)\n",
        "train_cluster_id = np.asarray(train_cluster_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXlPr1Pihml",
        "outputId": "0bc80bcd-3a46-485b-f6f1-ad1b7667975d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!python dvector_create.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"dvector_create.py\", line 119, in <module>\n",
            "    train_sequence = np.concatenate(train_sequence,axis=0)\n",
            "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
            "ValueError: need at least one array to concatenate\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
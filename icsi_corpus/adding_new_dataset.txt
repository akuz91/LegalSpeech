Steps to create new dataset to be included in training for speech embedder (in addition to TIMIT dataset):

1.  Get transcript and audio files
2.  For each speaker encountered:
    i.    Create speaker folder (unless already created)
    ii.   Save [start_time end_time transcript_text] as .txt file
    iii.  Save corresponding audio files for audio segments as .wav
3.  Remove .wav files that are <40KB, as well as with their corresponding .txt files (too small to process; buffer too short)
4.  Update config file to point to location of unprocessed data
5.  Run data_preprocess.py to create train_tisv and test_tisv folders; train/test automatically split 90/10 as per TIMIT 
6.  Check numpy speaker files for 0 length arrays. 
7.  If there are 0 length arrays present, find out which speaker name (folder) it belongs to by running check_file.py.
    i.  For ICSI Corpus:
        a. speaker10.npy (speaker folder: fe905) - TRAIN
        b. speaker35.npy (speaker folder: me908) - TRAIN
        c. speaker0.npy  (speaker folder: me907) - TEST
8.  Remove these speaker names (folders) from the unprocessed data location, and remove corresponding numpy speaker files from processed data location.
9.  **Place all processed train_tisv and test_tisv (TIMIT and new datasets) in same folder
10.  Update config file to point to location of unprocessed and processed data
11.  Continue training model: load saved model and continue training with all datasets (set config.yaml to restore and train)


Modifications to .py files when running on Prince:

1.  Remove exist_ok in data_preprocess.py


Modules needed for running scripts on Prince:

conda install -c auto pydub
conda install -c conda-forge pyyaml
module swap anaconda3  python/intel/2.7.12
module load librosa/intel/0.5.0
